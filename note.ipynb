{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a0c55561",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions, TesseractCliOcrOptions, PictureDescriptionApiOptions\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "from settings import AIConfig\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7df19ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"./data/System.pdf\"  # file path or URL\n",
    "\n",
    "# source = \"https://arxiv.org/pdf/2408.09869\"\n",
    "# picture_desc_api_option = PictureDescriptionApiOptions(\n",
    "#     url=os.environ.get('OLLAMA_BASE_URL'),\n",
    "#     prompt=\"Describe the content of this image in a single paragraph.\",\n",
    "#     params=dict(model=\"ollama:ministral-3:8b\", temperature=0.2),\n",
    "#     timeout=60\n",
    "# )\n",
    "\n",
    "# Configure PdfPipelineOptions for OCR with Tesseract CLI\n",
    "pipeline_options = PdfPipelineOptions(\n",
    "    # do_picture_description=True,\n",
    "    # picture_description_api_option=picture_desc_api_option,\n",
    "    # generate_picture_images=True,\n",
    "    # enable_remote_services=True,\n",
    "    # do_ocr=False,\n",
    "    # images_scale=2,\n",
    "    # ocr_options=TesseractCliOcrOptions(lang=[\"eng\"])\n",
    ")\n",
    "\n",
    "# Initialize DocumentConverter with the configured options\n",
    "converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(\n",
    "            pipeline_options=pipeline_options\n",
    "        )\n",
    "    }\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "971fd5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-07 00:16:00,404 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-12-07 00:16:00,581 - INFO - Going to convert document batch...\n",
      "2025-12-07 00:16:00,586 - INFO - Initializing pipeline for StandardPdfPipeline with options hash e15bc6f248154cc62f8db15ef18a8ab7\n",
      "2025-12-07 00:16:00,701 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-12-07 00:16:00,743 - INFO - Registered ocr engines: ['auto', 'easyocr', 'ocrmac', 'rapidocr', 'tesserocr', 'tesseract']\n",
      "2025-12-07 00:16:01,917 - INFO - Auto OCR model selected ocrmac.\n",
      "2025-12-07 00:16:01,924 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-12-07 00:16:01,941 - INFO - Registered layout engines: ['docling_layout_default', 'docling_experimental_table_crops_layout']\n",
      "2025-12-07 00:16:01,970 - INFO - Accelerator device: 'mps'\n",
      "2025-12-07 00:16:35,261 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-12-07 00:16:35,271 - INFO - Registered table structure engines: ['docling_tableformer']\n",
      "2025-12-07 00:16:36,243 - INFO - Accelerator device: 'mps'\n",
      "2025-12-07 00:16:37,035 - INFO - Processing document System.pdf\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m doc = \u001b[43mconverter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m markdown = doc.document.export_to_markdown()\n\u001b[32m      3\u001b[39m output_path = \u001b[33m\"\u001b[39m\u001b[33m./data/System.md\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/pypy/.venv/lib/python3.12/site-packages/pydantic/_internal/_validate_call.py:39\u001b[39m, in \u001b[36mupdate_wrapper_attributes.<locals>.wrapper_function\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(wrapped)\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper_function\u001b[39m(*args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/pypy/.venv/lib/python3.12/site-packages/pydantic/_internal/_validate_call.py:136\u001b[39m, in \u001b[36mValidateCallWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__pydantic_complete__:\n\u001b[32m    134\u001b[39m     \u001b[38;5;28mself\u001b[39m._create_validators()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpydantic_core\u001b[49m\u001b[43m.\u001b[49m\u001b[43mArgsKwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__return_pydantic_validator__:\n\u001b[32m    138\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__return_pydantic_validator__(res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/pypy/.venv/lib/python3.12/site-packages/docling/document_converter.py:265\u001b[39m, in \u001b[36mDocumentConverter.convert\u001b[39m\u001b[34m(self, source, headers, raises_on_error, max_num_pages, max_file_size, page_range)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;129m@validate_call\u001b[39m(config=ConfigDict(strict=\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconvert\u001b[39m(\n\u001b[32m    249\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    255\u001b[39m     page_range: PageRange = DEFAULT_PAGE_RANGE,\n\u001b[32m    256\u001b[39m ) -> ConversionResult:\n\u001b[32m    257\u001b[39m     all_res = \u001b[38;5;28mself\u001b[39m.convert_all(\n\u001b[32m    258\u001b[39m         source=[source],\n\u001b[32m    259\u001b[39m         raises_on_error=raises_on_error,\n\u001b[32m   (...)\u001b[39m\u001b[32m    263\u001b[39m         page_range=page_range,\n\u001b[32m    264\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m265\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mall_res\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/pypy/.venv/lib/python3.12/site-packages/docling/document_converter.py:288\u001b[39m, in \u001b[36mDocumentConverter.convert_all\u001b[39m\u001b[34m(self, source, headers, raises_on_error, max_num_pages, max_file_size, page_range)\u001b[39m\n\u001b[32m    285\u001b[39m conv_res_iter = \u001b[38;5;28mself\u001b[39m._convert(conv_input, raises_on_error=raises_on_error)\n\u001b[32m    287\u001b[39m had_result = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconv_res\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconv_res_iter\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhad_result\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m    290\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraises_on_error\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconv_res\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m        \u001b[49m\u001b[43mConversionStatus\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSUCCESS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[43m        \u001b[49m\u001b[43mConversionStatus\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPARTIAL_SUCCESS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    293\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/pypy/.venv/lib/python3.12/site-packages/docling/document_converter.py:364\u001b[39m, in \u001b[36mDocumentConverter._convert\u001b[39m\u001b[34m(self, conv_input, raises_on_error)\u001b[39m\n\u001b[32m    362\u001b[39m             \u001b[38;5;28;01myield\u001b[39;00m item\n\u001b[32m    363\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprocess_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[43m        \u001b[49m\u001b[43melapsed\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmonotonic\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmonotonic\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/pypy/.venv/lib/python3.12/site-packages/docling/document_converter.py:411\u001b[39m, in \u001b[36mDocumentConverter._process_document\u001b[39m\u001b[34m(self, in_doc, raises_on_error)\u001b[39m\n\u001b[32m    407\u001b[39m valid = (\n\u001b[32m    408\u001b[39m     \u001b[38;5;28mself\u001b[39m.allowed_formats \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m in_doc.format \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.allowed_formats\n\u001b[32m    409\u001b[39m )\n\u001b[32m    410\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m     conv_res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_doc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraises_on_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraises_on_error\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    413\u001b[39m     error_message = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile format not allowed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00min_doc.file\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/pypy/.venv/lib/python3.12/site-packages/docling/document_converter.py:434\u001b[39m, in \u001b[36mDocumentConverter._execute_pipeline\u001b[39m\u001b[34m(self, in_doc, raises_on_error)\u001b[39m\n\u001b[32m    432\u001b[39m pipeline = \u001b[38;5;28mself\u001b[39m._get_pipeline(in_doc.format)\n\u001b[32m    433\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pipeline \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m434\u001b[39m     conv_res = \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_doc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraises_on_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraises_on_error\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    436\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m raises_on_error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/pypy/.venv/lib/python3.12/site-packages/docling/pipeline/base_pipeline.py:72\u001b[39m, in \u001b[36mBasePipeline.execute\u001b[39m\u001b[34m(self, in_doc, raises_on_error)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m TimeRecorder(\n\u001b[32m     68\u001b[39m         conv_res, \u001b[33m\"\u001b[39m\u001b[33mpipeline_total\u001b[39m\u001b[33m\"\u001b[39m, scope=ProfilingScope.DOCUMENT\n\u001b[32m     69\u001b[39m     ):\n\u001b[32m     70\u001b[39m         \u001b[38;5;66;03m# These steps are building and assembling the structure of the\u001b[39;00m\n\u001b[32m     71\u001b[39m         \u001b[38;5;66;03m# output DoclingDocument.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m         conv_res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_document\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconv_res\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     73\u001b[39m         conv_res = \u001b[38;5;28mself\u001b[39m._assemble_document(conv_res)\n\u001b[32m     74\u001b[39m         \u001b[38;5;66;03m# From this stage, all operations should rely only on conv_res.output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/pypy/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py:651\u001b[39m, in \u001b[36mStandardPdfPipeline._build_document\u001b[39m\u001b[34m(self, conv_res)\u001b[39m\n\u001b[32m    648\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    650\u001b[39m \u001b[38;5;66;03m# 2) drain - pull whatever is ready from the output side\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m651\u001b[39m out_batch = \u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutput_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.05\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m itm \u001b[38;5;129;01min\u001b[39;00m out_batch:\n\u001b[32m    653\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m itm.run_id != run_id:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/pypy/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py:149\u001b[39m, in \u001b[36mThreadedQueue.get_batch\u001b[39m\u001b[34m(self, size, timeout)\u001b[39m\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m remaining <= \u001b[32m0\u001b[39m:\n\u001b[32m    148\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m []\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_not_empty\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    151\u001b[39m     \u001b[38;5;28mself\u001b[39m._not_empty.wait()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.11-macos-aarch64-none/lib/python3.12/threading.py:359\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m         gotit = \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    360\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    361\u001b[39m         gotit = waiter.acquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "doc = converter.convert(source)\n",
    "markdown = doc.document.export_to_markdown()\n",
    "output_path = \"./data/System.md\"\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(markdown)\n",
    "print(f\"Saved markdown to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "06d37ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 83.97it/s]\n"
     ]
    }
   ],
   "source": [
    "import lancedb\n",
    "from lancedb.pydantic import LanceModel, Vector\n",
    "from lancedb.embeddings import get_registry\n",
    "from docling.document_converter import DocumentConverter\n",
    "from docling.chunking import HybridChunker\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "MD_FILE_PATH = \"./data/M2.md\"  # Your converted markdown file\n",
    "DB_URI = \"./lancedb_data\"    # This will create a local folder\n",
    "TABLE_NAME = \"engineering_docs\"\n",
    "\n",
    "embedding_func = get_registry().get(\"sentence-transformers\").create()\n",
    "\n",
    "class DocChunk(LanceModel):\n",
    "    \"\"\"\n",
    "    Pydantic schema for LanceDB.\n",
    "    \"\"\"\n",
    "    text: str = embedding_func.SourceField() # The text to be embedded\n",
    "    vector: Vector(embedding_func.ndims()) = embedding_func.VectorField() # type: ignore # Auto-generated\n",
    "    \n",
    "    # Metadata fields\n",
    "    filename: str\n",
    "    chunk_index: int\n",
    "    chunk_type: str  # e.g., \"text\", \"table\", \"code\"\n",
    "\n",
    "db = lancedb.connect(\"./lancedb_data\")\n",
    "table_name = \"engineering_notes\"\n",
    "\n",
    "table = db.create_table(table_name, schema=DocChunk, mode=\"overwrite\")\n",
    "def process_and_store_md(file_path: str):\n",
    "    print(f\"Processing: {file_path}\")\n",
    "    converter = DocumentConverter()\n",
    "    result = converter.convert(file_path)\n",
    "    doc = result.document\n",
    "    chunker = HybridChunker(\n",
    "        max_tokens=800, # Increased slightly as Gemini handles larger contexts well\n",
    "        merge_peers=True,\n",
    "    )\n",
    "\n",
    "    chunk_iter = chunker.chunk(doc)\n",
    "    data_to_ingest = []\n",
    "    for i, chunk in enumerate(chunk_iter):\n",
    "        headers = [h for h in chunk.meta.headings]\n",
    "        hierarchy_path = \" > \".join(headers) if headers else \"Root\"\n",
    "        content_type = \"mixed\"\n",
    "        if \"```\" in chunk.text:\n",
    "            content_type = \"code\"\n",
    "        elif \"|\" in chunk.text and \"-|-\" in chunk.text:\n",
    "            content_type = \"table\"\n",
    "\n",
    "        entry = {\n",
    "            \"text\": chunk.text,\n",
    "            \"filename\": os.path.basename(\"M2.md\"),\n",
    "            \"chunk_type\": content_type,\n",
    "            \"chunk_index\": i,\n",
    "        }\n",
    "        data_to_ingest.append(entry)\n",
    "    if data_to_ingest:\n",
    "        table.add(data_to_ingest)\n",
    "        print(f\"Successfully added {len(data_to_ingest)} chunks to LanceDB.\")\n",
    "    else:\n",
    "        print(\"No chunks generated.\")\n",
    "    table.create_fts_index(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f7efb1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-06 18:21:57,076 - INFO - detected formats: [<InputFormat.MD: 'md'>]\n",
      "2025-12-06 18:21:57,078 - INFO - Going to convert document batch...\n",
      "2025-12-06 18:21:57,080 - INFO - Initializing pipeline for SimplePipeline with options hash 995a146ad601044538e6a923bea22f4e\n",
      "2025-12-06 18:21:57,083 - INFO - Processing document M2.md\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: ./data/M2.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-06 18:21:57,449 - INFO - Finished converting document M2.md in 0.38 sec.\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (589 > 512). Running this sequence through the model will result in indexing errors\n",
      "Batches: 100%|██████████| 2/2 [00:00<00:00,  4.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added 38 chunks to LanceDB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "process_and_store_md(MD_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9a2a4b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 48.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    - Originally proposed by Barry Boehm the spira...\n",
       "1    - Scrum is an agile method that focuses on man...\n",
       "2    - The four basic process activities of specifi...\n",
       "3    The stages of the waterfall model directly ref...\n",
       "4    - Product development where a software company...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = table.search(\"Explain spiral model\").distance_type(\"cosine\").limit(5)\n",
    "res.to_pandas()['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06d5829",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 35.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid search results:\n",
      "                                                text  \\\n",
      "0  - The four basic process activities of specifi...   \n",
      "1  There are two kinds of software product:\\n1. G...   \n",
      "2  - The principal responsibility of software pro...   \n",
      "3  - Product development where a software company...   \n",
      "4  What is software?, Answer = Computer programs ...   \n",
      "5  - Agile methods are incremental development me...   \n",
      "6  1. Heterogeneity Increasingly, systems are req...   \n",
      "7  The systematic approach that is used in softwa...   \n",
      "8  - Dissatisfaction with the overheads involved ...   \n",
      "9  In the image, we can see the words \"Concurrent...   \n",
      "\n",
      "                                              vector filename  chunk_index  \\\n",
      "0  [0.008744788, -0.015853986, -0.018221293, -0.0...    M2.md           11   \n",
      "1  [-0.049120296, -0.051378325, 0.04316983, -0.07...    M2.md            1   \n",
      "2  [-0.055930406, 0.038180914, 0.007761431, 0.033...    M2.md           32   \n",
      "3  [0.008349403, -0.0031605244, -0.028572725, -0....    M2.md           28   \n",
      "4  [-0.015082242, -0.013660297, 0.018372888, -0.0...    M2.md            0   \n",
      "5  [-0.024218027, 0.037628993, -0.01779887, -0.04...    M2.md           24   \n",
      "6  [-0.013628552, 0.0014113149, 0.010096464, -0.0...    M2.md            6   \n",
      "7  [-0.054157816, 0.001620905, 0.01395818, -0.073...    M2.md            5   \n",
      "8  [-0.023254372, 0.108587265, 0.002895469, 0.013...    M2.md           25   \n",
      "9  [-0.016522754, 0.0020479916, -0.025442922, -0....    M2.md           10   \n",
      "\n",
      "  chunk_type  _relevance_score  \n",
      "0      mixed          0.031025  \n",
      "1      mixed          0.030550  \n",
      "2      mixed          0.029670  \n",
      "3      mixed          0.016393  \n",
      "4      mixed          0.016393  \n",
      "5      mixed          0.016129  \n",
      "6      mixed          0.016129  \n",
      "7      mixed          0.015873  \n",
      "8      mixed          0.015625  \n",
      "9      mixed          0.015385  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from lancedb.rerankers import RRFReranker\n",
    "reranker = RRFReranker()\n",
    "results = (\n",
    "    table.search(\n",
    "        \"Different types of software development methodologies\",\n",
    "        query_type=\"hybrid\",\n",
    "        vector_column_name=\"vector\",\n",
    "        fts_columns=\"text\",\n",
    "    )\n",
    "    .rerank(reranker)\n",
    "    .limit(10)\n",
    "    .to_list()\n",
    ")\n",
    "\n",
    "print(\"Hybrid search results:\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68607a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydantic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
